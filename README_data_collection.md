# ReplicaÃ§Ã£o â€” Coleta de Dados (Jupyter Notebooks Reproducibility)

Este diretÃ³rio contÃ©m o script e os artefatos para **coletar metadados** de notebooks Jupyter pÃºblicos no GitHub, seguindo (e atualizando) a metodologia de Pimentel et al. (2019).

## âš™ï¸ PrÃ©-requisitos

- Python 3.10+
- Um **token de acesso do GitHub** com permissÃ£o de leitura pÃºblica (`GITHUB_TOKEN`)
- DependÃªncias do `requirements.txt`

```bash
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
```

## ğŸš€ Uso

Coletar notebooks criados em 2025 (exemplo), limitando a ~2000 itens e salvando o CSV:

```bash
export GITHUB_TOKEN=ghp_XXXXXXXXXXXXXXXXXXXXXXXXXXXX
python scripts/collect_notebooks.py   --date-start 2025-01-01   --date-end   2025-09-28   --max-items  2000   --output     data/notebooks_metadata.csv
```

> ObservaÃ§Ã£o: o GitHub Search API retorna no mÃ¡ximo 1000 resultados por consulta. O script **divide automaticamente o intervalo de datas** para respeitar esse limite.

## ğŸ“¦ SaÃ­da

Um CSV com **uma linha por notebook** e colunas como:

- IdentificaÃ§Ã£o do repositÃ³rio, datas e estrelas
- Caminho do arquivo `.ipynb`
- Contagem de cÃ©lulas por tipo, execuÃ§Ã£o e outputs
- MÃ©tricas de ordem de execuÃ§Ã£o (ambiguidade, _skips_, _out-of-order_)
- AST de cÃ³digo: imports, funÃ§Ãµes, classes, controle de fluxo, _testing_ hints
- HeurÃ­sticas de **uso/colagem por IA** (marcadores em markdown/cÃ³digo)
- PresenÃ§a de arquivos de dependÃªncias (`requirements.txt`, `setup.py`, `Pipfile`)
- HeurÃ­stica de **paths absolutos**

## ğŸ§ª ValidaÃ§Ã£o / Qualidade

- JSON de notebook validado com `nbformat`
- Filtros para notebooks **Python** por padrÃ£o (pode desabilitar)
- _Backoff_ e _retry_ para lidar com _rate limits_
- DetecÃ§Ã£o de dependÃªncias varre a Ã¡rvore completa do branch padrÃ£o

## ğŸ”’ Ã‰tica e limites

- Apenas repositÃ³rios **pÃºblicos**
- Sem execuÃ§Ã£o de notebooks neste estÃ¡gio de coleta (apenas **metadados**)
- Dados sensÃ­veis nÃ£o sÃ£o coletados
