# ReplicaÃ§Ã£o â€” Coleta e ExecuÃ§Ã£o (Jupyter Notebooks Reproducibility)

Este diretÃ³rio contÃ©m scripts e artefatos para **coletar metadados** e **executar notebooks** Jupyter pÃºblicos no GitHub, seguindo (e atualizando) a metodologia de Pimentel et al. (2019). Inclui tambÃ©m um **summarizer** para estatÃ­sticas descritivas.

## âš™ï¸ PrÃ©-requisitos

- Python 3.10+
- Um **token do GitHub** com leitura pÃºblica (`GITHUB_TOKEN`)
- DependÃªncias do `requirements.txt`

```bash
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
```

Crie a pasta de saÃ­das:

```bash
mkdir -p data/outputs
```

## ğŸ”‘ Token do GitHub

```bash
export GITHUB_TOKEN=ghp_XXXXXXXXXXXXXXXXXXXXXXXXXXXX
```

> Dica: use token **sÃ³ de leitura pÃºblica**. Se vazou, **revogue** no GitHub.

---

## ğŸš€ 1) Coleta de metadados (sem executar notebooks)

Script: `scripts/collect_notebooks.py`  
Descobre repositÃ³rios por `created:` (GitHub Search **repositories**), varre a Ã¡rvore do branch padrÃ£o e processa cada `.ipynb` (sem clonar o repo).

### Exemplos de uso

**Janâ€“Set/2025 (exemplo, ~2000 notebooks):**

```bash
python scripts/collect_notebooks.py \
  --date-start 2025-01-01 \
  --date-end   2025-09-28 \
  --max-items  1000 \
  --output     data/outputs/notebooks_2025_jan-set.csv
```

```bash
python3 scripts/collect_notebooks.py \
 --date-start 2025-01-01 --date-end 2025-01-31 \
 --max-items 200 --output data/notebooks_jan.csv \
 --require-outputs
```

**Janela curta (sanidade):**

```bash
python scripts/collect_notebooks.py \
  --date-start 2025-03-01 \
  --date-end   2025-03-07 \
  --max-items  100 \
  --output     data/outputs/notebooks_2025_mar_1w.csv
```

**Coleta â€œhistÃ³ricaâ€ (comparabilidade 2019):**

```bash
python scripts/collect_notebooks.py \
  --date-start 2019-01-01 \
  --date-end   2019-01-05 \
  --max-items  200 \
  --output     data/outputs/notebooks_2019_jan_1w.csv
```

> O script divide automaticamente o intervalo para respeitar o limite de **1000 resultados por consulta** da API de busca.

### SaÃ­da

CSV com **uma linha por notebook** contendo:

- IdentificaÃ§Ã£o do repositÃ³rio (`repo_full_name`, `repo_stars`, datas)
- Caminho do `.ipynb` no repositÃ³rio e URL
- Contagem de cÃ©lulas por tipo; execuÃ§Ã£o e outputs
- MÃ©tricas de ordem de execuÃ§Ã£o (ambiguidade, _skips_, _out-of-order_)
- AST de cÃ³digo: imports, funÃ§Ãµes, classes, controle de fluxo, _testing_ hints
- HeurÃ­sticas de **IA** (marcadores em markdown/cÃ³digo)
- PresenÃ§a de arquivos de dependÃªncias (`requirements.txt`, `setup.py`, `Pipfile`)
- HeurÃ­stica de **paths absolutos**

ValidaÃ§Ãµes embutidas:

- `nbformat` (parse do JSON)
- Filtro por **Python** (padrÃ£o)
- _Retry/backoff_ para _rate limits_
- _Fallback_ para `download_url` em arquivos grandes (LFS)

---

## ğŸ§ª 2) Executor controlado (nbclient) â€” **opcional nesta fase**

Script: `scripts/execute_notebooks.py`  
Clona cada repositÃ³rio (shallow), cria **env isolado por repositÃ³rio** (venv), aplica polÃ­tica de dependÃªncias e **executa** o notebook com **timeout**.

PolÃ­ticas:

- `--policy relaxed` (padrÃ£o): instala baseline mÃ­nima (pip, wheel, nbclient, ipykernel).
- `--policy strict`: tenta instalar `requirements.txt` / `Pipfile` / `setup.py`/`pyproject` do repositÃ³rio.

```bash
python scripts/execute_notebooks.py \
  --input-csv  data/outputs/notebooks_2025_mar_1w.csv \
  --output-csv data/outputs/execution_results_2025_mar_1w.csv \
  --policy     strict \
  --timeout    30 \
  --limit      50
```

**SaÃ­da (`data/outputs/execution_results_*.csv`):**

- `repo_full_name`, `repo_default_branch`, `file_path`
- Metadados relevantes (`kernel_name`, `language`, `python_version_declared`)
- **Resultados de execuÃ§Ã£o**: `exec_ok`, `error`, `exc_name`, `failed_cell_index`, `elapsed_s`

> ObservaÃ§Ã£o: esta etapa Ã© **computacionalmente cara** e comparÃ¡vel ao desenho de Pimentel et al. (ambiente limpo + timeout + ordem de execuÃ§Ã£o do notebook).

---

## ğŸ“Š 3) Summarizer (estatÃ­sticas descritivas)

Script: `scripts/summarize_collection.py`  
LÃª o CSV de coleta (e opcionalmente o CSV de execuÃ§Ã£o) e imprime estatÃ­sticas descritivas.

```bash
python scripts/summarize_collection.py \
  --collection-csv data/outputs/notebooks_2025_mar_1w.csv \
  --exec-csv       data/outputs/execution_results_2025_mar_1w.csv \
  | tee data/outputs/summary_2025_mar_1w.txt
```

Produz (exemplos):

- Contagens e percentuais: `nb_ok_parse=True`, `language=python`, `deps_any=True`, `has_unambiguous_order=True`
- Mediana/mÃ©dia de `n_code`, `n_markdown`, `% code executed`
- **Top imports** agregados (a partir de `top_imports_json`)
- Se execuÃ§Ãµes fornecidas: taxa de sucesso e erros mais comuns

---

## ğŸ§¹ Boas prÃ¡ticas / Qualidade

- **Garbage in, garbage out**: use `nb_ok_parse=True` e `language=python` para anÃ¡lises comparÃ¡veis a 2019.
- Para _reprodutibilidade_, rode o executor com polÃ­tica **estrita** e relacione erros a `deps_*`, _ordem de execuÃ§Ã£o_, _paths absolutos_, etc.
- FaÃ§a janelas menores (semanas/meses) e **consolide**:

```bash
# exemplo de concatenaÃ§Ã£o mantendo apenas um cabeÃ§alho
awk 'FNR==1 && NR!=1 {next} {print}' data/outputs/notebooks_2025_*.csv > data/outputs/notebooks_2025_all.csv
```

---

## ğŸ”’ Ã‰tica e limites

- Apenas repositÃ³rios **pÃºblicos**
- Coleta Ã© **somente metadados**; execuÃ§Ã£o Ã© opcional e controlada
- NÃ£o coletamos dados sensÃ­veis; respeitamos _rate limits_ e termos da API

---

### Troubleshooting rÃ¡pido

- **Mostra â€œColetando notebooks: 0itâ€** â†’ vocÃª estÃ¡ na versÃ£o antiga (busca por **cÃ³digo** com `created:`). A correta mostra **â€œVarredura de repositÃ³riosâ€**.
- **`nb_ok_parse=False` em muitos casos** â†’ notebooks grandes (LFS). Garanta que seu coletor estÃ¡ com o **fallback para `download_url`**.
- **`TypeError: expected string, got list`** â†’ normalizamos `cell.source` com helper `as_text(...)`.
